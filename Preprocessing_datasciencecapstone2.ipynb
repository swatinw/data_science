{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "104e93f7",
   "metadata": {},
   "source": [
    "# Pre-Processing and Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf4fdfb",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e59819b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import __version__ as sklearn_version\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV, learning_curve\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c02109",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aada07d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>record_ID</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week</th>\n",
       "      <td>2011-01-17</td>\n",
       "      <td>2011-01-17</td>\n",
       "      <td>2011-01-17</td>\n",
       "      <td>2011-01-17</td>\n",
       "      <td>2011-01-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store_id</th>\n",
       "      <td>8091</td>\n",
       "      <td>8091</td>\n",
       "      <td>8091</td>\n",
       "      <td>8091</td>\n",
       "      <td>8091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sku_id</th>\n",
       "      <td>216418</td>\n",
       "      <td>216419</td>\n",
       "      <td>216425</td>\n",
       "      <td>216233</td>\n",
       "      <td>217390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_price</th>\n",
       "      <td>99.0375</td>\n",
       "      <td>99.0375</td>\n",
       "      <td>133.95</td>\n",
       "      <td>133.95</td>\n",
       "      <td>141.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_price</th>\n",
       "      <td>111.8625</td>\n",
       "      <td>99.0375</td>\n",
       "      <td>133.95</td>\n",
       "      <td>133.95</td>\n",
       "      <td>141.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_featured_sku</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_display_sku</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>units_sold</th>\n",
       "      <td>20</td>\n",
       "      <td>28</td>\n",
       "      <td>19</td>\n",
       "      <td>44</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>2011</td>\n",
       "      <td>2011</td>\n",
       "      <td>2011</td>\n",
       "      <td>2011</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_price</th>\n",
       "      <td>219</td>\n",
       "      <td>219</td>\n",
       "      <td>219</td>\n",
       "      <td>219</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>revenue</th>\n",
       "      <td>4380</td>\n",
       "      <td>6132</td>\n",
       "      <td>4161</td>\n",
       "      <td>9636</td>\n",
       "      <td>11388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          0           1           2           3           4\n",
       "record_ID                 1           2           3           4           5\n",
       "week             2011-01-17  2011-01-17  2011-01-17  2011-01-17  2011-01-17\n",
       "store_id               8091        8091        8091        8091        8091\n",
       "sku_id               216418      216419      216425      216233      217390\n",
       "total_price         99.0375     99.0375      133.95      133.95     141.075\n",
       "base_price         111.8625     99.0375      133.95      133.95     141.075\n",
       "is_featured_sku           0           0           0           0           0\n",
       "is_display_sku            0           0           0           0           0\n",
       "units_sold               20          28          19          44          52\n",
       "year                   2011        2011        2011        2011        2011\n",
       "month                     1           1           1           1           1\n",
       "day                      17          17          17          17          17\n",
       "average_price           219         219         219         219         219\n",
       "revenue                4380        6132        4161        9636       11388"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged = pd.read_csv('/Users/swatisharma/Documents/GitHub/Capstone2_Demand_Forecast/df_merged_features.csv')\n",
    "df_merged.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b1c3af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the column \"week\"\n",
    "df_merged = df_merged.drop('week', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f89e3efa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150150, 13)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7eab194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_ID</th>\n",
       "      <th>store_id</th>\n",
       "      <th>sku_id</th>\n",
       "      <th>total_price</th>\n",
       "      <th>base_price</th>\n",
       "      <th>is_featured_sku</th>\n",
       "      <th>is_display_sku</th>\n",
       "      <th>units_sold</th>\n",
       "      <th>year</th>\n",
       "      <th>day</th>\n",
       "      <th>...</th>\n",
       "      <th>M_3</th>\n",
       "      <th>M_4</th>\n",
       "      <th>M_5</th>\n",
       "      <th>M_6</th>\n",
       "      <th>M_7</th>\n",
       "      <th>M_8</th>\n",
       "      <th>M_9</th>\n",
       "      <th>M_10</th>\n",
       "      <th>M_11</th>\n",
       "      <th>M_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>8091</td>\n",
       "      <td>216418</td>\n",
       "      <td>99.0375</td>\n",
       "      <td>111.8625</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>2011</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>8091</td>\n",
       "      <td>216419</td>\n",
       "      <td>99.0375</td>\n",
       "      <td>99.0375</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>2011</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>8091</td>\n",
       "      <td>216425</td>\n",
       "      <td>133.9500</td>\n",
       "      <td>133.9500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>2011</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>8091</td>\n",
       "      <td>216233</td>\n",
       "      <td>133.9500</td>\n",
       "      <td>133.9500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>2011</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>8091</td>\n",
       "      <td>217390</td>\n",
       "      <td>141.0750</td>\n",
       "      <td>141.0750</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>2011</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150145</th>\n",
       "      <td>212638</td>\n",
       "      <td>9984</td>\n",
       "      <td>223245</td>\n",
       "      <td>235.8375</td>\n",
       "      <td>235.8375</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>2013</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150146</th>\n",
       "      <td>212639</td>\n",
       "      <td>9984</td>\n",
       "      <td>223153</td>\n",
       "      <td>235.8375</td>\n",
       "      <td>235.8375</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>2013</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150147</th>\n",
       "      <td>212642</td>\n",
       "      <td>9984</td>\n",
       "      <td>245338</td>\n",
       "      <td>357.6750</td>\n",
       "      <td>483.7875</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>2013</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150148</th>\n",
       "      <td>212643</td>\n",
       "      <td>9984</td>\n",
       "      <td>547934</td>\n",
       "      <td>141.7875</td>\n",
       "      <td>191.6625</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2013</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150149</th>\n",
       "      <td>212644</td>\n",
       "      <td>9984</td>\n",
       "      <td>679023</td>\n",
       "      <td>234.4125</td>\n",
       "      <td>234.4125</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>2013</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150150 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        record_ID  store_id  sku_id  total_price  base_price  is_featured_sku  \\\n",
       "0               1      8091  216418      99.0375    111.8625                0   \n",
       "1               2      8091  216419      99.0375     99.0375                0   \n",
       "2               3      8091  216425     133.9500    133.9500                0   \n",
       "3               4      8091  216233     133.9500    133.9500                0   \n",
       "4               5      8091  217390     141.0750    141.0750                0   \n",
       "...           ...       ...     ...          ...         ...              ...   \n",
       "150145     212638      9984  223245     235.8375    235.8375                0   \n",
       "150146     212639      9984  223153     235.8375    235.8375                0   \n",
       "150147     212642      9984  245338     357.6750    483.7875                1   \n",
       "150148     212643      9984  547934     141.7875    191.6625                0   \n",
       "150149     212644      9984  679023     234.4125    234.4125                0   \n",
       "\n",
       "        is_display_sku  units_sold  year  day  ...    M_3    M_4    M_5  \\\n",
       "0                    0          20  2011   17  ...  False  False  False   \n",
       "1                    0          28  2011   17  ...  False  False  False   \n",
       "2                    0          19  2011   17  ...  False  False  False   \n",
       "3                    0          44  2011   17  ...  False  False  False   \n",
       "4                    0          52  2011   17  ...  False  False  False   \n",
       "...                ...         ...   ...  ...  ...    ...    ...    ...   \n",
       "150145               0          38  2013    7  ...  False  False  False   \n",
       "150146               0          30  2013    7  ...  False  False  False   \n",
       "150147               1          31  2013    7  ...  False  False  False   \n",
       "150148               1          12  2013    7  ...  False  False  False   \n",
       "150149               0          15  2013    7  ...  False  False  False   \n",
       "\n",
       "          M_6    M_7    M_8    M_9   M_10   M_11   M_12  \n",
       "0       False  False  False  False  False  False  False  \n",
       "1       False  False  False  False  False  False  False  \n",
       "2       False  False  False  False  False  False  False  \n",
       "3       False  False  False  False  False  False  False  \n",
       "4       False  False  False  False  False  False  False  \n",
       "...       ...    ...    ...    ...    ...    ...    ...  \n",
       "150145  False  False  False   True  False  False  False  \n",
       "150146  False  False  False   True  False  False  False  \n",
       "150147  False  False  False   True  False  False  False  \n",
       "150148  False  False  False   True  False  False  False  \n",
       "150149  False  False  False   True  False  False  False  \n",
       "\n",
       "[150150 rows x 24 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create dummy or indicator features for categorical variable \"month\"\n",
    "pd.get_dummies(df_merged, columns = [\"month\"], prefix = \"M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5fc16b",
   "metadata": {},
   "source": [
    "# Train/Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fe59f4",
   "metadata": {},
   "source": [
    "Partition sizes with a 70/30 train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d3ae6b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105105.0, 45045.0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_merged) * .7, len(df_merged) * .3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be66b157",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_merged.drop(columns='units_sold'), \n",
    "                                                    df_merged.units_sold, test_size=0.3, \n",
    "                                                    random_state=47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc7ed84f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((105105, 12), (45045, 12))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a042281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((105105,), (45045,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da1a28cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((105105, 8), (45045, 8))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Code task 1#\n",
    "#Save the ''record_ID', 'total_price', 'revenue', 'month' columns from the train/test data into units_sold_train and units_sold_test\n",
    "#Then drop those columns from `X_train` and `X_test`. Use 'inplace=True'\n",
    "column_list = ['record_ID', 'total_price', 'revenue', 'month']\n",
    "column_list_train = X_train[column_list]\n",
    "column_list_test = X_test[column_list]\n",
    "X_train.drop(columns=column_list, inplace=True)\n",
    "X_test.drop(columns=column_list, inplace=True)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c97e5ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "store_id             int64\n",
       "sku_id               int64\n",
       "base_price         float64\n",
       "is_featured_sku      int64\n",
       "is_display_sku       int64\n",
       "year                 int64\n",
       "day                  int64\n",
       "average_price        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Code task 2#\n",
    "#Check the `dtypes` attribute of `X_train` to verify all features are numeric\n",
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "952a6f49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "store_id             int64\n",
       "sku_id               int64\n",
       "base_price         float64\n",
       "is_featured_sku      int64\n",
       "is_display_sku       int64\n",
       "year                 int64\n",
       "day                  int64\n",
       "average_price        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Code task 3#\n",
    "#Repeat this check for the test split in `X_test`\n",
    "X_test.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91662a9",
   "metadata": {},
   "source": [
    "We have only numeric features in our X now!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5db17b3",
   "metadata": {},
   "source": [
    "# Initial Not-Even-A-Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c25f249",
   "metadata": {},
   "source": [
    "A good place to start is to see how good the mean is as a predictor. In other words, what if we simply say our best guess is the average price?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9673931d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51.773569287855004"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Code task 4#\n",
    "#Calculate the mean of `y_train`\n",
    "train_mean = y_train.mean()\n",
    "train_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcbd794",
   "metadata": {},
   "source": [
    "sklearn's DummyRegressor easily does this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "136f58aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[51.77356929]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Code task 5#\n",
    "#Fit the dummy regressor on the training data\n",
    "#Hint, call its `.fit()` method with `X_train` and `y_train` as arguments\n",
    "#Then print the object's `constant_` attribute and verify it's the same as the mean above\n",
    "dumb_reg = DummyRegressor(strategy='mean')\n",
    "dumb_reg.fit(X_train, y_train)\n",
    "dumb_reg.constant_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b02c04",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d663c048",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code task 6#\n",
    "#Calculate the R^2 as defined above\n",
    "def r_squared(y, ypred):\n",
    "    \"\"\"R-squared score.\n",
    "    \n",
    "    Calculate the R-squared, or coefficient of determination, of the input.\n",
    "    \n",
    "    Arguments:\n",
    "    y -- the observed values\n",
    "    ypred -- the predicted values\n",
    "    \"\"\"\n",
    "    ybar = np.sum(y) / len(y) #yes, we could use np.mean(y)\n",
    "    sum_sq_tot = np.sum((y - ybar)**2) #total sum of squares error\n",
    "    sum_sq_res = np.sum((y - ypred)**2) #residual sum of squares error\n",
    "    R2 = 1.0 - sum_sq_res / sum_sq_tot\n",
    "    return R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "18d1e9aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([51.77356929, 51.77356929, 51.77356929, 51.77356929, 51.77356929])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tr_pred_ = train_mean * np.ones(len(y_train))\n",
    "y_tr_pred_[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fe48eb3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([51.77356929, 51.77356929, 51.77356929, 51.77356929, 51.77356929])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tr_pred = dumb_reg.predict(X_train)\n",
    "y_tr_pred[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e10697e",
   "metadata": {},
   "source": [
    "We see that DummyRegressor produces exactly the same results and saves us having to mess about broadcasting the mean (or whichever other statistic we used. It also gives us an object with fit() and predict() methods as well so we can use them as conveniently as any other sklearn estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4bd85ada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_squared(y_train, y_tr_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e15019d",
   "metadata": {},
   "source": [
    "Exactly as expected, if we use the average value as your prediction, we get an \n",
    " of zero on our training set. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5c275d",
   "metadata": {},
   "source": [
    "Make our predictions by creating an array of length the size of the test set with the single value of the (training) mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a4299861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.154020817031089e-05"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_te_pred = train_mean * np.ones(len(y_test))\n",
    "r_squared(y_test, y_te_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c746da70",
   "metadata": {},
   "source": [
    "# Mean Absolute Error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923faaa7",
   "metadata": {},
   "source": [
    "This is very simply the average of the absolute errors:\n",
    "\n",
    " \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bf963832",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code task 7#\n",
    "#Calculate the MAE as defined above\n",
    "def mae(y, ypred):\n",
    "    \"\"\"Mean absolute error.\n",
    "    \n",
    "    Calculate the mean absolute error of the arguments\n",
    "\n",
    "    Arguments:\n",
    "    y -- the observed values\n",
    "    ypred -- the predicted values\n",
    "    \"\"\"\n",
    "    abs_error = np.abs(y - ypred)\n",
    "    mae = np.mean(abs_error)\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3e4f150c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35.4215600222051"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae(y_train, y_tr_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "038ca3e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35.19770865228837"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae(y_test, y_te_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b48353",
   "metadata": {},
   "source": [
    "Mean absolute error is arguably the most intuitive of all the metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d230e07",
   "metadata": {},
   "source": [
    "# Mean Squared Error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5983fd68",
   "metadata": {},
   "source": [
    "Another common metric (and an important one internally for optimizing machine learning models) is the mean squared error. This is simply the average of the square of the errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5ed8ddde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code task 8#\n",
    "#Calculate the MSE as defined above\n",
    "def mse(y, ypred):\n",
    "    \"\"\"Mean square error.\n",
    "    \n",
    "    Calculate the mean square error of the arguments\n",
    "\n",
    "    Arguments:\n",
    "    y -- the observed values\n",
    "    ypred -- the predicted values\n",
    "    \"\"\"\n",
    "    sq_error = (y - ypred)**2\n",
    "    mse = np.mean(sq_error)\n",
    "    return mse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bd1e48cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3687.8621585603128"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse(y_train, y_tr_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "75f36194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3478.246355202695"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse(y_test, y_te_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1bce8889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([60.7277709 , 58.97665941])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt([mse(y_train, y_tr_pred), mse(y_test, y_te_pred)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82cf12d4",
   "metadata": {},
   "source": [
    "# sklearn metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96213b1",
   "metadata": {},
   "source": [
    "Functions are good, but you don't want to have to define functions every time we want to assess performance. sklearn.metrics provides many commonly used metrics, included the ones above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7919e9d",
   "metadata": {},
   "source": [
    "R-squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0807879a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, -3.154020817031089e-05)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_train, y_tr_pred), r2_score(y_test, y_te_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9b0849",
   "metadata": {},
   "source": [
    "Mean absolute error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6f0a343a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35.4215600222051, 35.19770865228837)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_train, y_tr_pred), mean_absolute_error(y_test, y_te_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b67cad",
   "metadata": {},
   "source": [
    "Mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6d9596de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3687.8621585603128, 3478.246355202695)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_train, y_tr_pred), mean_squared_error(y_test, y_te_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798d578e",
   "metadata": {},
   "source": [
    "Explore what happens when we reverse the order of the arguments and compare behaviour of sklearn's function and yours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a9a2dff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, -1.8261408901788884e+31)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train set - sklearn\n",
    "# correct order, incorrect order\n",
    "r2_score(y_train, y_tr_pred), r2_score(y_tr_pred, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a23ff6d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-3.154020817031089e-05, -6.889376687366168e+31)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test set - sklearn\n",
    "# correct order, incorrect order\n",
    "r2_score(y_test, y_te_pred), r2_score(y_te_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "057b58a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, -1.8261408901788884e+31)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train set - using our homebrew function\n",
    "# correct order, incorrect order\n",
    "r_squared(y_train, y_tr_pred), r_squared(y_tr_pred, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "218f0109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-3.154020817031089e-05, -6.889376687366168e+31)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test set - using our homebrew function\n",
    "# correct order, incorrect order\n",
    "r_squared(y_test, y_te_pred), r_squared(y_te_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4ffb76",
   "metadata": {},
   "source": [
    "# Initial Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c174072",
   "metadata": {},
   "source": [
    "Impute missing values with median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c402e4ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "store_id             9371.0000\n",
       "sku_id             222087.0000\n",
       "base_price            205.9125\n",
       "is_featured_sku         0.0000\n",
       "is_display_sku          0.0000\n",
       "year                 2012.0000\n",
       "day                    16.0000\n",
       "average_price         219.0000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are the values we'll use to fill in any missing values\n",
    "X_defaults_median = X_train.median()\n",
    "X_defaults_median"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bb9b5f",
   "metadata": {},
   "source": [
    "Apply the imputation to both train and test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8265df5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code task 9#\n",
    "#Call `X_train` and `X_test`'s `fillna()` method, passing `X_defaults_median` as the values to use\n",
    "#Assign the results to `X_tr` and `X_te`, respectively\n",
    "X_tr = X_train.fillna(X_defaults_median)\n",
    "X_te = X_test.fillna(X_defaults_median)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df10f53",
   "metadata": {},
   "source": [
    "# Scale the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbab647",
   "metadata": {},
   "source": [
    "As we have features measured in many different units, with numbers that vary by orders of magnitude, start off by scaling them to put them all on a consistent scale. The StandardScaler scales each feature to zero mean and unit variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dd2b3885",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code task 10#\n",
    "#Call the StandardScaler`s fit method on `X_tr` to fit the scaler\n",
    "#then use it's `transform()` method to apply the scaling to both the train and test split\n",
    "#data (`X_tr` and `X_te`), naming the results `X_tr_scaled` and `X_te_scaled`, respectively\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_tr)\n",
    "X_tr_scaled = scaler.transform(X_tr)\n",
    "X_te_scaled = scaler.transform(X_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053fcb73",
   "metadata": {},
   "source": [
    "Train the model on the train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1d65e6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression().fit(X_tr_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1939d8c",
   "metadata": {},
   "source": [
    "Make predictions using the model on both train and test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5e6a427d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code task 11#\n",
    "#Call the `predict()` method of the model (`lm`) on both the (scaled) train and test data\n",
    "#Assign the predictions to `y_tr_pred` and `y_te_pred`, respectively\n",
    "y_tr_pred = lm.predict(X_tr_scaled)\n",
    "y_te_pred = lm.predict(X_te_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6610b754",
   "metadata": {},
   "source": [
    "Assess model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "68c5ed12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2389111294479428, 0.2481345818574201)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# r^2 - train, test\n",
    "median_r2 = r2_score(y_train, y_tr_pred), r2_score(y_test, y_te_pred)\n",
    "median_r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73566bd5",
   "metadata": {},
   "source": [
    "Recall that you estimated ticket price by simply using a known average. As expected, this produced an \n",
    " of zero for both the training and test set, because \n",
    " tells us how much of the variance you're explaining beyond that of using just the mean, and you were using just the mean. Here we see that our simple linear regression model explains over 80% of the variance on the train set and over 70% on the test set. Clearly you are onto something, although the much lower value for the test set suggests you're overfitting somewhat. This isn't a surprise as you've made no effort to select a parsimonious set of features or deal with multicollinearity in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bee55e93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30.403394492429545, 30.140327971178646)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Code task 12#\n",
    "#Now calculate the mean absolute error scores using `sklearn`'s `mean_absolute_error` function\n",
    "# as we did above for R^2\n",
    "# MAE - train, test\n",
    "median_mae = mean_absolute_error(y_train, y_tr_pred), mean_absolute_error(y_test, y_te_pred)\n",
    "median_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7d757cb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2806.7908450103405, 2615.090669753271)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Code task 13#\n",
    "#And also do the same using `sklearn`'s `mean_squared_error`\n",
    "# MSE - train, test\n",
    "median_mse = mean_squared_error(y_train, y_tr_pred), mean_squared_error(y_test, y_te_pred)\n",
    "median_mse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641c9d53",
   "metadata": {},
   "source": [
    "# Impute missing values with the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "39d3b745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "store_id             9201.097636\n",
       "sku_id             254978.269045\n",
       "base_price            219.370829\n",
       "is_featured_sku         0.095647\n",
       "is_display_sku          0.132686\n",
       "year                 2011.830788\n",
       "day                    15.695562\n",
       "average_price         219.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Code task 14#\n",
    "#As we did for the median above, calculate mean values for imputing missing values\n",
    "# These are the values we'll use to fill in any missing values\n",
    "X_defaults_mean = X_train.mean()\n",
    "X_defaults_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b8b49d",
   "metadata": {},
   "source": [
    "Apply the imputation to both train and test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "988009fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = X_train.fillna(X_defaults_mean)\n",
    "X_te = X_test.fillna(X_defaults_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77792027",
   "metadata": {},
   "source": [
    "Scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ab222306",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_tr)\n",
    "X_tr_scaled = scaler.transform(X_tr)\n",
    "X_te_scaled = scaler.transform(X_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5838cafd",
   "metadata": {},
   "source": [
    "Train the model on the train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b8c3e6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression().fit(X_tr_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a59b7c",
   "metadata": {},
   "source": [
    "Make predictions using the model on both train and test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "469353cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr_pred = lm.predict(X_tr_scaled)\n",
    "y_te_pred = lm.predict(X_te_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c38cc7",
   "metadata": {},
   "source": [
    "Assess model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "324f4dff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2389111294479428, 0.2481345818574201)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_train, y_tr_pred), r2_score(y_test, y_te_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fb320ab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30.403394492429545, 30.140327971178646)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_train, y_tr_pred), mean_absolute_error(y_test, y_te_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c2448e43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2806.7908450103405, 2615.090669753271)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_train, y_tr_pred), mean_squared_error(y_test, y_te_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e360fb8",
   "metadata": {},
   "source": [
    "These results don't seem very different to when you used the median for imputing missing values. Perhaps it doesn't make much difference here. Maybe your overtraining dominates. Maybe other feature transformations, such as taking the log, would help. You could try with just a subset of features rather than using all of them as inputs.\n",
    "\n",
    "To perform the median/mean comparison, you copied and pasted a lot of code just to change the function for imputing missing values. It would make more sense to write a function that performed the sequence of steps:\n",
    "\n",
    "impute missing values\n",
    "scale the features\n",
    "train a model\n",
    "calculate model performance\n",
    "But these are common steps and sklearn provides something much better than writing custom functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07c50e0",
   "metadata": {},
   "source": [
    "# Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba699b3f",
   "metadata": {},
   "source": [
    "One of the most important and useful components of sklearn is the pipeline. In place of panda's fillna DataFrame method, there is sklearn's SimpleImputer. Remember the first linear model above performed the steps:\n",
    "\n",
    "replace missing values with the median for each feature\n",
    "scale the data to zero mean and unit variance\n",
    "train a linear regression model\n",
    "and all these steps were trained on the train split and then applied to the test split for assessment.\n",
    "\n",
    "The pipeline below defines exactly those same steps. Crucially, the resultant Pipeline object has a fit() method and a predict() method, just like the LinearRegression() object itself. Just as you might create a linear regression model and train it with .fit() and predict with .predict(), you can wrap the entire process of imputing and feature scaling and regression in a single object you can train with .fit() and predict with .predict(). And that's basically a pipeline: a model on steroids.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e4ee2e",
   "metadata": {},
   "source": [
    "Define the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ace798cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(\n",
    "    SimpleImputer(strategy='median'), \n",
    "    StandardScaler(), \n",
    "    LinearRegression()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b197d2db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.pipeline.Pipeline"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "635be788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hasattr(pipe, 'fit'), hasattr(pipe, 'predict')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ac1285",
   "metadata": {},
   "source": [
    "In next step we will perform modeling and build two to three different models including linear regression, randome forest etc., identify the best one and perform hyperparameter tuning. Also, access the data quality using various metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9a7cd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
